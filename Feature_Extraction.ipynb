{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zwj93/test/blob/master/Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vaUFuSr-t3G",
        "colab_type": "code",
        "outputId": "1c459e9c-1183-407c-a9a7-05ab75553390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5pptJ70BD1l",
        "colab_type": "code",
        "outputId": "8f33e013-6a7d-4dd3-b110-a5e871a77b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
            "\u001b[K     |████████████████████████████████| 215.6MB 125kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 34.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9mP4jb9B_fa",
        "colab_type": "code",
        "outputId": "b28543b5-7055-4ddf-dc7a-a4f4b7f9842d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os       #importing os to set environment variable\n",
        "def install_java():\n",
        "    #install openjdk\n",
        "    !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "    #set environment variable\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "    !java -version       #check java version\n",
        "install_java()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.3\" 2019-04-16\n",
            "OpenJDK Runtime Environment (build 11.0.3+7-Ubuntu-1ubuntu218.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.3+7-Ubuntu-1ubuntu218.04.1, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fxqR8CSCEGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, os.path, time\n",
        "from pyspark import SparkContext\n",
        "import string\n",
        "from ast import literal_eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP-n7uzGDTSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import *\n",
        "from pyspark.mllib.feature import HashingTF\n",
        "from pyspark.mllib.feature import IDF\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# create the spark context\n",
        "sc = SparkContext()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHIjsrzWDuAJ",
        "colab_type": "code",
        "outputId": "cbdc9675-3ef8-46cf-8267-ef85c8d72413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "print(os.listdir())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'drive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyFMhMlqDZfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = time.time()\n",
        "PUNCTUATION = set(string.punctuation)\n",
        "\n",
        "def tokenize(text):\n",
        "    stemmeren = PorterStemmer()\n",
        "    lowercase = [tkn.lower() for tkn in text]\n",
        "    rm_pun = []\n",
        "    for i in lowercase:\n",
        "        i = i.replace('\\\\n', '')\n",
        "        punrm = ''.join([charc for charc in i if not charc in PUNCTUATION])\n",
        "        rm_pun.append(punrm)\n",
        "    \n",
        "    stop_rm = [wd for wd in rm_pun if not wd in STOPWORDSEN]\n",
        "    stem = [stemmeren.stem(wd) for wd in stop_rm]\n",
        "    return [j for j in stem if j]\n",
        "\n",
        "#total 59 crash\n",
        "filePath = \"drive/My Drive/Colab Notebooks/crash.txt\"\n",
        "crashData = sc.textFile(filePath).map(lambda r:str(r)).map(lambda line: line.split(\" \"))\n",
        "crashDataRDD = crashData.map(lambda t:(0,t))\n",
        "\n",
        "#total 219 nearCrash\n",
        "filePath = \"drive/My Drive/Colab Notebooks/nearCrash.txt\"\n",
        "nearCrashData = sc.textFile(filePath).map(lambda r:str(r)).map(lambda line: line.split(\" \"))\n",
        "nearCrashRDD = nearCrashData.map(lambda t:(1,t))\n",
        "\n",
        "#total 9 otherEvent\n",
        "filePath = \"drive/My Drive/Colab Notebooks/otherType.txt\"\n",
        "otherEventData = sc.textFile(filePath).map(lambda r:str(r)).map(lambda line: line.split(\" \"))\n",
        "otherEventDataRDD = otherEventData.map(lambda t:(2,t))\n",
        "\n",
        "experimentData = crashDataRDD + nearCrashRDD + otherEventDataRDD\n",
        "\n",
        "# load stop words list\n",
        "stopWordsPath = \"drive/My Drive/Colab Notebooks/stop-word-list.txt\"\n",
        "stopWordsSet  = sc.textFile(stopWordsPath).collect()\n",
        "STOPWORDSEN   = set(stopWordsSet)\n",
        "\n",
        "tokens_data = experimentData.map(lambda x: (x[0], tokenize(x[1])))\n",
        "tokens_data.saveAsTextFile(\"tokens_data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knfo7v6tDdBA",
        "colab_type": "code",
        "outputId": "0275aa6e-2153-45f6-d6cf-c00e8e3dd3a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "cleanedData = sc.textFile(\"tokens_data/\").map(lambda r:literal_eval(str(r)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-b1cccd11f97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcleanedData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokens_data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcleanedData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: collect() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1HnzDJ0EfRp",
        "colab_type": "code",
        "outputId": "ad1b6802-50f3-415e-f1ce-bbbadf3b2691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# feature extraction\n",
        "distictNumberOfWords = cleanedData.flatMap(lambda x:x[1]).distinct().count()\n",
        "htf = HashingTF(distictNumberOfWords+200)\n",
        "hashedData = cleanedData.map(lambda x: LabeledPoint(x[0], htf.transform(x[1])))\n",
        "hashedData.saveAsTextFile(\"hashed_data/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.mllib.feature.HashingTF'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK32iUoUIE0x",
        "colab_type": "code",
        "outputId": "51cc8b1e-29c0-46a1-e569-74b362194b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "pip install pyspark.mllib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark.mllib\n",
            "\u001b[31m  ERROR: Could not find a version that satisfies the requirement pyspark.mllib (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pyspark.mllib\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r8mRNawEkem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.mllib.linalg import Vectors\n",
        "freqs = [Vectors.dense([0.0, 1.0, 0.0, 3.0]), Vectors.dense([1.0, 4.0, 2.0, 3.0]), Vectors.dense([0.0, 0.0, 2.0, 3.0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-_3QFWpIDVE",
        "colab_type": "code",
        "outputId": "7ca1e706-c270-45b5-f753-b1898f79cac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "freqs\n",
        "data = sc.parallelize(freqs)\n",
        "model = IDF().fit(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DenseVector([0.0, 1.0, 0.0, 3.0]),\n",
              " DenseVector([1.0, 4.0, 2.0, 3.0]),\n",
              " DenseVector([0.0, 0.0, 2.0, 3.0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KQvkJ2fEnUm",
        "colab_type": "code",
        "outputId": "620db5b3-c0d5-4ab0-daf9-7127d8327ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(type(model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.mllib.feature.IDFModel'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ2krTtGIu-A",
        "colab_type": "code",
        "outputId": "0d7b8adc-724a-426c-bf1f-4402f5d623fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.transform(Vectors.dense([2.0, 3.0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([1.3863, 0.863])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPJYS_GuIwe7",
        "colab_type": "code",
        "outputId": "ca315df6-c71d-405f-a700-be457ebaa612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math\n",
        "math.log(4 / 3) * 3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8630462173553426"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S__Z5IbFIy2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}